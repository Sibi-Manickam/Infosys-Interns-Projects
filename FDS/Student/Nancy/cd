# -*- coding: utf-8 -*-
"""Nancy.ipynb
Automatically generated by Colab.
"""

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

# read data
df = pd.read_csv('creditcard.csv')

# The first five lines from dataset
df.head()

# Original shape of the dataset
df.shape

# Column names
df.columns

# Statistical description of the dataset
df.describe()

# Information about the dataset
df.info()

# Number of missing values in each column
df.isnull().sum()

# Number of fraud cases
valid = len(df[df['Class'] == 0]) # Valid transaction if Class = 0
fraud = len(df[df['Class'] == 1]) # Fraud transaction if Class = 1

Outlier_Fraction = (fraud/(valid+fraud)) * 100
print('The outlier fraction is :' , Outlier_Fraction)
print('The valid transactions are :'  , valid )
print('The fraud transactions are :'  , fraud )

print('Amount details of valid transaction')
valid_info= df[(df['Class']==0)]
valid_info.Amount.describe()

print('Amount details of fraud transaction')
fraud_info = df[df['Class'] ==1]
fraud_info.Amount.describe()

"""The dataset has a big problem: most transactions are normal, not fraud. If we use this data as it is, Model might learn that fraud almost never happens and make a lot of mistakes when trying to spot it."""

# fraud and valid trasactions for better understanding
count_classes = pd.value_counts(df['Class'], sort = True ).sort_index()
count_classes.plot(kind = 'bar' ,rot = 0 ,colormap ='viridis')

plt.title ( "Fraud Class Histogram" )
plt.xlabel( "Class" )
plt.ylabel( "Frequency" )

# Distribution in Time
sns.kdeplot(df['Time'])
plt.show()

# Distribution in Amount of transaction
sns.kdeplot(df['Amount'])
plt.show()

# V columns are already scaled
# only scale the columns 'Amount' and 'Time'
# After this we must remove the old columns and replace them with the new, making a new dataset with the right values

from sklearn.preprocessing import StandardScaler
stc = StandardScaler()
df['scaled_amount'] = stc.fit_transform(df['Amount'].values.reshape(-1,1))
df['scaled_time'] = stc.fit_transform(df['Time'].values.reshape(-1,1))
df.drop(['Amount' , 'Time'] , axis = 1 , inplace = True )
scaled_amount = df['scaled_amount']
scaled_time   = df['scaled_time']
df.drop(['scaled_amount' , 'scaled_time'] , axis = 1 , inplace = True )
df.insert(0 , 'scaled_amount' , scaled_amount)
df.insert(1 , 'scaled_time' , scaled_time)
df.head()

"""To address the imbalance in the dataset and improve the performance of the algorithms in distinguishing between valid and fraudulent transactions, a sub-sample with 492 valid transactions and 492 fraud transactions is created. By balancing the dataset in this manner, algorithms will perform better and recognize the patterns that differentiate fraudulent from legitimate transactions, enhancing their ability to accurately classify future transactions. This approach will help mitigate the impact of the initial imbalance observed in the dataset and improve the overall effectiveness of the fraud detection system."""

df = df.sample(frac=1)

# take all the fraud transactions from the original dataset
fraud_df =  df[df['Class'] ==1]

# take 492 random choices of valid transactions, in order to create the new dataframe
valid_df = df.loc[np.random.choice(df.index, 492, replace=False)]

# join them
normal_distributed_df = pd.concat([fraud_df, valid_df],axis=0)

# shuffle the new dataframe and make it normal distributed
new_df = normal_distributed_df.sample(frac=1, random_state=42)
new_df = pd.DataFrame(new_df)
new_df.head()

# new dataset which contains 984 transactions in random order (492 valid and 492 fraud)
new_df.shape

import seaborn as sns
# new dataset of the equally possible transactions
print('Distribution of the Classes in the new dataset')

sns.countplot(x='Class', data=new_df, palette="Set2")
plt.title('Equally Distributed Classes', fontsize=13)
plt.show()

# ratio of the new dataframe

print("The percentage of normal transactions is: ", (len(new_df[new_df['Class']==0])/len(new_df)))
print("The percentage of fraud transactions is: ", (len(new_df[new_df['Class']==1])/len(new_df)))
print("The total number of transactions in resampled data: ", len(new_df))

# heatmap
corr1 = new_df.corr()
fig, ax = plt.subplots(figsize=(20,13))
sns.heatmap(corr1, cmap='viridis', annot_kws={'size':20}, linewidths= 0.05)
ax.set_title('SubSample Correlation Matrix \n (use for reference)', fontsize=13)
plt.show()

"""IQR METHOD

"""

# Find the positive correletaion which can be outliers
# Positive correlation: The higher the feature value the probability increases that it will be a fraudulent transaction

f, axes = plt.subplots(ncols=5, figsize=(25,15))

sns.boxplot(x='Class' , y ='V2',  data = new_df, ax=axes[0])
sns.boxplot(x='Class' , y ='V3',  data = new_df, ax=axes[1])
sns.boxplot(x='Class' , y ='V4',  data = new_df, ax=axes[2])
sns.boxplot(x='Class' , y ='V7',  data = new_df, ax=axes[3])
sns.boxplot(x='Class' , y ='V20', data = new_df, ax=axes[4])

print('Positive Correlation Boxtplos', '\n')
plt.show()

# removal of the extreme outliers from top two positive correlation
# First is the V20

V20_fraud = new_df['V20'].loc[new_df['Class'] == 1 ].values

q25_V20 = np.percentile(V20_fraud , 25)
q75_V20 = np.percentile(V20_fraud , 75)

print('The 25th Quartile is :' , q25_V20)
print('The 75th Quantile is :' , q75_V20)

V20_iqr = q75_V20 - q25_V20

print('The IQR of V20 is :' , V20_iqr , '\n')

V20_off = 1.5 * V20_iqr
V20_lower = q25_V20 - V20_off
V20_upper = q75_V20 + V20_off

print('The V20 that we will remove is :' , V20_off)
print('The min point is :' , V20_lower)
print('The max point is :' , V20_upper , '\n')

outliers_V20 = [i for i in V20_fraud if i < V20_lower or i > V20_upper ]
new_df_V20 = new_df.drop(new_df[(new_df['V20'] > V20_upper) | (new_df['V20'] < V20_lower)].index)

print('The number of the outliers is : ', len(outliers_V20))
print('The number of transactions after the outliers removes is :' , len(new_df_V20))
print('The new dataset after we remove the outliers of v20 is :' , new_df_V20.shape)

# comparision of the boxplots before and after we remove the outliers of V20.

f,(ax1, ax2) = plt.subplots(1, 2, figsize=(10,10))
sns.boxplot( x="Class", y="V20", data=new_df, ax=ax1 )
sns.boxplot( x="Class", y="V20", data=new_df_V20, ax=ax2 )
print('Before and After we apply the IQR method and remove the outliers of V20', '\n')

# Removal of the extreme outliers from top two positive correlation
# Second is the V3

V3_fraud = new_df['V3'].loc[new_df['Class'] == 1 ].values
q25_V3 = np.percentile(V3_fraud , 25)
q75_V3 = np.percentile(V3_fraud , 75)
print('The 25th Quartile is :'  , q25_V3)
print('The 75th Quantile is : ' , q75_V3)

V3_iqr = q75_V3 - q25_V3
print('The IQR of V3 is :' , V3_iqr , '\n')

V3_off = 1.5 * V3_iqr
V3_lower = q25_V3 - V3_off
V3_upper = q75_V3 + V3_off
print('The V3 tha we will remove is :' , V3_off)
print('The min point is :' , V3_lower)
print('The max point is :' , V3_upper ,'\n')

outliers_V3 = [i for i in V3_fraud if i < V3_lower or i > V3_upper ]
new_df_V3 = new_df.drop(new_df[(new_df['V3'] > V3_upper) | (new_df['V3'] < V3_lower)].index)
print('The number of the outliers is : ', len(outliers_V3))
print('The number of transactions after the outliers removes is :' , len(new_df_V3))
print('The new dataset after we remove the outliers of V3 is :' , new_df_V3.shape)

# comparision of the boxplots before and after the removal of the outliers of V3

f,(ax1, ax2) = plt.subplots(1, 2, figsize=(10,10))

sns.boxplot(x="Class", y="V3", data=new_df, ax=ax1)
sns.boxplot(x="Class", y="V3", data=new_df_V3, ax=ax2)

print('Before and After we apply the IQR method and remove the outliers of V3' , '\n')

# Negative correlation: The lower the feature value,the probability decreases that it will be a fraudulent transaction.

f, axes = plt.subplots(ncols=5, figsize=(25,15))

sns.boxplot( x='Class' , y ='V10', data = new_df, ax=axes[0] )
sns.boxplot( x='Class' , y ='V12', data = new_df, ax=axes[1] )
sns.boxplot( x='Class' , y ='V14', data = new_df, ax=axes[2] )
sns.boxplot( x='Class' , y ='V16', data = new_df, ax=axes[3] )
sns.boxplot( x='Class' , y ='V17', data = new_df, ax=axes[4] )

print('Negative Correlation Boxtplos' , '\n')
plt.show()

# Removal of the extreme outliers from top two negative correlation
# First the V10

V10_fraud = new_df['V10'].loc[new_df['Class'] == 1 ].values

q25_V10 = np.percentile(V10_fraud , 25)
q75_V10 = np.percentile(V10_fraud , 75)

print('The 25th Quartile is :' , q25_V10)
print('The 75th Quantile is :' , q75_V10)

V10_iqr = q75_V10 - q25_V10

print('The IQR of V10 is :' , V10_iqr , '\n')

V10_off = 1.5* V10_iqr
V10_lower = q25_V10 - V10_off
V10_upper = q75_V10 + V10_off

print('The V10 tha we will remove is :' , V10_off)
print('The min point is :' , V10_lower)
print('The max point is :' , V10_upper , '\n')

outliers_V10 = [i for i in V10_fraud if i < V10_lower or i > V10_upper ]
new_df_V10 = new_df.drop(new_df[(new_df['V10'] > V10_upper) | (new_df['V10'] < V10_lower)].index)

print('The number of the outliers is : ', len(outliers_V10))
print('The number of transactions after the outliers removes is :' , len(new_df_V10))
print('The new dataset after we remove the outliers of V10 is :' ,new_df_V10.shape)

# Comparision of the boxplots before and after removal of the outliers of V10

f,(ax1, ax2) = plt.subplots(1, 2, figsize=(10,10))

sns.boxplot( x="Class", y="V10", data=new_df, ax = ax1 )
sns.boxplot( x="Class", y="V10", data=new_df_V10, ax = ax2 )

print('Before and After we apply the IQR method and remove the outliers of V10' , '\n')

# Removal of the extreme outliers from top two negative correlation
# First the V14

V14_fraud = new_df['V14'].loc[new_df['Class'] == 1 ].values

q25_V14 = np.percentile(V14_fraud , 25)
q75_V14 = np.percentile(V14_fraud , 75)

print('The 25th Quartile is :' , q25_V14)
print('The 75th Quantile is : ' , q75_V14)

V14_iqr = q75_V14 - q25_V14

print('The IQR of V14 is :' , V14_iqr, '\n')

V14_off = 1.5 * V14_iqr
V14_lower = q25_V14 - V14_off
V14_upper = q75_V14 + V14_off

print('The V14 tha we will remove is :' , V14_off)
print('The min point is :' , V14_lower)
print('The max point is :' , V14_upper,'\n')

outliers_V14 = [i for i in V14_fraud if i < V14_lower or i > V14_upper ]
new_df_V14 = new_df.drop(new_df[(new_df['V14'] > V14_upper) | (new_df['V14'] < V14_lower)].index)

print('The number of the outliers is : ', len(outliers_V14))
print('The number of transactions after the outliers removes is :' , len(new_df_V14))
print('The new dataset after we remove the outliers of V14 is :' ,new_df_V14.shape)

# comparision of boxplots before and after removal of the outliers of V14

f,(ax1, ax2) = plt.subplots(1, 2, figsize=(10,10))

sns.boxplot( x="Class", y="V14", data=new_df, ax=ax1)
sns.boxplot( x="Class", y="V14", data=new_df_V14, ax=ax2)

print('Before and After we apply the IQR method and remove the outliers of V14' , '\n' )

X = df.drop(['Class'], axis=1)
y = df['Class']

# Spliting the dataset in train set and test set, using sklearn libraly

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state = 42 )

from sklearn.metrics import (confusion_matrix, roc_curve, classification_report, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score)

# ISOLATION FOREST TREE MODEL

from sklearn.ensemble import IsolationForest

isf = IsolationForest(random_state = 42, max_samples = len(X)).fit(X)    # Fitting the model
y_prediction = isf.predict(X)                                            # Prediction using trained model

# The isolation forest use (-1,1) in order to predict the result
# But we have valid = 0 and fraud = 1 , so we must make some changes  before we run it

y_prediction[y_prediction ==  1] = 0                                    # Valid transactions are labelled as 0, but we change it to valid = 1
y_prediction[y_prediction == -1] = 1                                    # Fraudulent transactions are labelled as 1, but we change it to fraud = -1

errors = (y_prediction != y).sum()                                      # Total number of errors is calculated

print('The errors of the Isolation Forest model is ', errors , '\n')

print("Model Accuracy:", round(accuracy_score(y_prediction , y),2))
print("Model Precision:", round(precision_score(y_prediction , y),2))
print("Model Recall:", round(recall_score(y_prediction , y),2))
print("Model F1-Score:", round(f1_score(y_prediction , y),2))
print("Model ROC:", round(roc_auc_score(y_prediction , y),2) , '\n')


conf_matrix=confusion_matrix(y_prediction,y)
labels= ['Valid', 'Fraud']
plt.figure(figsize=(6, 6))

sns.heatmap(pd.DataFrame(conf_matrix), xticklabels= labels, yticklabels= labels,
            linewidths= 0.05 ,annot=True, fmt="d" , cmap='BuPu')

print(classification_report(y_prediction , y) , '\n')

plt.title("Isolation Forest Classifier - Confusion Matrix")
plt.ylabel('True Value')
plt.xlabel('Predicted Value')
plt.show()

# RANDOM FOREST CLASSIFIER MODEL

from sklearn.ensemble import RandomForestClassifier

rfc=RandomForestClassifier( random_state = 42 )
rfc.fit(X_train, y_train)
Y_pred=rfc.predict(X_test)

print("Model Accuracy:", round(accuracy_score(y_test, Y_pred),2))
print("Model Precision:", round(precision_score(y_test, Y_pred),2))
print("Model Recall:", round(recall_score(y_test, Y_pred),2))
print("Model F1-Score:", round(f1_score(y_test, Y_pred),2))
print("Model ROC:", round(roc_auc_score(y_test, Y_pred),2) , '\n')

conf_matrix=confusion_matrix(y_test, Y_pred)
labels= ['Valid', 'Fraud']
plt.figure(figsize=(6, 6))

sns.heatmap(pd.DataFrame(conf_matrix), xticklabels= labels, yticklabels= labels,
            linewidths= 0.05 ,annot=True, fmt="d" , cmap='BuPu')

print(classification_report(y_test, Y_pred, target_names=labels) , '\n')

plt.title("Random Forest Classifier - Confusion Matrix")
plt.ylabel('True Value')
plt.xlabel('Predicted Value')
plt.show()

# LOGISTIC REGRESSION MODEL

from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression(random_state = 42)
logreg.fit(X_train, y_train)
Y_pred1 = logreg.predict(X_test)

print("Model Accuracy:", round(accuracy_score(y_test, Y_pred1),2))
print("Model Precision:", round(precision_score(y_test, Y_pred1),2))
print("Model Recall:", round(recall_score(y_test, Y_pred1),2))
print("Model F1-Score:", round(f1_score(y_test, Y_pred1),2) , '\n')


conf_matrix1 = confusion_matrix(y_test, Y_pred1)
plt.figure(figsize=(6, 6))
labels= ['Valid', 'Fraud']

sns.heatmap(pd.DataFrame(conf_matrix1),annot=True, fmt='d',
            linewidths= 0.05 ,cmap='BuPu',xticklabels= labels, yticklabels= labels)

print(classification_report(y_test, Y_pred1, target_names=labels) , '\n')

plt.title('Logistic Regression - Confusion Matrix')
plt.ylabel('True Value')
plt.xlabel('Predicted Value')
plt.show()

# DECISSION TREE CLASSIFIER MODEL

from sklearn.tree import DecisionTreeClassifier

dtc = DecisionTreeClassifier(random_state = 42)
dtc.fit(X_train,y_train)
Y_pred2 = dtc.predict(X_test)
conf_matrix2 = confusion_matrix(y_test , Y_pred2)

print("Model Accuracy:", round(accuracy_score(y_test, Y_pred2),2))
print("Model Precision:", round(precision_score(y_test, Y_pred2),2))
print("Model Recall:", round(recall_score(y_test, Y_pred2),2))
print("Model F1-Score:", round(f1_score(y_test, Y_pred2),2) , '\n')

conf_matrix2 = confusion_matrix(y_test, Y_pred2)
plt.figure(figsize=(6, 6))
labels= ['Valid', 'Fraud']

sns.heatmap(pd.DataFrame(conf_matrix2),annot=True, fmt='d',linewidths= 0.05 ,cmap='BuPu',
            xticklabels= labels, yticklabels= labels)

print(classification_report(y_test,Y_pred2,target_names=labels) , '\n')

plt.title('Decission Tree Classifier - Confusion Matrix')
plt.ylabel('True Value')
plt.xlabel('Predicted Value')
plt.show()

# NAIVE BAYES CLASSIFIER

from sklearn.naive_bayes import BernoulliNB

NB = BernoulliNB()
NB.fit(X_train,y_train)
Y_pred3 = NB.predict(X_test)
conf_matrix_nb = confusion_matrix(y_test , Y_pred3)

print("Model Accuracy:", round(accuracy_score(y_test, Y_pred3),2))
print("Model Precision:", round(precision_score(y_test, Y_pred3),2))
print("Model Recall:", round(recall_score(y_test, Y_pred3),2))
print("Model F1-Score:", round(f1_score(y_test, Y_pred3),2) , '\n')

conf_matrix2 = confusion_matrix(y_test, Y_pred3)
plt.figure(figsize=(6, 6))
labels= ['Valid', 'Fraud']

sns.heatmap(pd.DataFrame(conf_matrix2),annot=True, fmt='d',linewidths= 0.05 ,cmap='BuPu',
            xticklabels= labels, yticklabels= labels)

print(classification_report(y_test,Y_pred2,target_names=labels) , '\n')

plt.title('Naive Bayes Classifier - Confusion Matrix')
plt.ylabel('True Value')
plt.xlabel('Predicted Value')
plt.show()

# SVM CLASSIFIER MODEL
# SVM = Support Vector Machine

from sklearn.svm import SVC

svm_clf = SVC()
svm_clf.fit(X_train,y_train)

Y_pred4 = svm_clf.predict(X_test)

conf_matrix_svm = confusion_matrix(y_test,Y_pred4)

print("Model Accuracy:", round(accuracy_score(y_test, Y_pred4),2))
print("Model Precision:", round(precision_score(y_test, Y_pred4),2))
print("Model Recall:", round(recall_score(y_test,Y_pred4),2))
print("Model F1-Score:", round(f1_score(y_test, Y_pred4),2) , '\n')

plt.figure(figsize=(6, 6))
labels= ['Valid', 'Fraud']

sns.heatmap(pd.DataFrame(conf_matrix2),annot=True, fmt='d',linewidths= 0.05 ,cmap='BuPu',
            xticklabels= labels, yticklabels= labels)

print(classification_report(y_test,Y_pred2,target_names=labels) , '\n')

plt.title('SVM Classifier - Confusion Matrix')
plt.ylabel('True Value')
plt.xlabel('Predicted Value')
plt.show()
