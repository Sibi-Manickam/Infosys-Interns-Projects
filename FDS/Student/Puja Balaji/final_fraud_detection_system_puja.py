# -*- coding: utf-8 -*-
"""Final_Fraud_Detection_System_Puja.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jqvpLTWz_u-vwF27IBCzBegwudbFA1Vr
"""

print(sklearn.__version__)

#Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
import xgboost as xgb
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from plotly.subplots import make_subplots
from warnings import filterwarnings

filterwarnings("ignore")

#Loading dataset
data = pd.read_csv('/content/synthetic_financial_data.csv')
data.head()

data.shape

data.info()

df1 = data.select_dtypes('object')
df1

df2 = data.select_dtypes('int64')
df2

data.describe().T

df2.describe().T

# Calculating the correlation matrix
correlation_matrix = df2.corr()

# Plotting the correlation matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

data.isnull().sum()

print(f'There are {data.duplicated().sum()} duplicate rows')

# Convert transaction_time into datetime
data['transaction_time'] = pd.to_datetime(data['transaction_time'])
data['transaction_time'].info()

data.tail(3)

sns.countplot(data=data,x='is_fraudulent',hue='is_fraudulent',palette='bright')
plt.show()

plt.figure(figsize=(8,4))
sns.histplot(data, x='amount', hue='is_fraudulent', multiple="stack")
plt.title('Distribution of Transaction Amounts by Fraudulent Status')
plt.show()

data_fraud = data[data.is_fraudulent==1]
data_fraud.head()

#Age Intervals
def age_interval(x):
    if x < 20:
        return "Less than 20"
    elif x >=20 and x < 30:
        return "Between 20 and 30"
    elif x >=30 and x < 40:
        return "Between 30 and 40"
    elif x >=40 and x < 50:
        return "Between 40 and 50"
    elif x >=50 and x < 60:
        return "Between 50 and 60"
    else:
        return "Larger than 60"

data_fraud.loc[:, 'age_intervals'] = data.customer_age.map(lambda x: age_interval(x))
age_order = [ 'Larger than 60',
             'Between 50 and 60',
             'Between 40 and 50',
             'Between 30 and 40',
             'Between 20 and 30',
             'Less than 20']

age_intervals_count = data_fraud.age_intervals.value_counts()
age_intervals_count = age_intervals_count.reindex(index=age_order)
print(age_intervals_count)

#Age Vs Number of frauds
age = sns.countplot(y='age_intervals',
                  data=data_fraud,
                  order=age_order, palette='bright',hue='age_intervals',
                  width=0.5)
age.set_title('Age vs Number of frauds', fontdict = { 'fontsize': 16, 'fontweight':'bold'})
age.set_xlabel('Count', fontsize=15, fontweight='bold')
age.set_ylabel('Age', fontsize=15, fontweight='bold')
plt.show()

mode_category = data_fraud['purchase_category'].mode()[0]
print(f"The most frequent category for fraudulent transactions is: {mode_category}")

#Purchase category Vs Number of frauds
cat = sns.countplot(y = 'purchase_category',
                  data=data_fraud,
                  width=0.9, palette='bright',hue='purchase_category',
                  order=data_fraud.purchase_category.value_counts().index)

cat.set_title('Purchase category vs Number of frauds', fontdict = { 'fontsize': 16, 'fontweight':'bold'})
cat.set_xlabel('Count', fontsize=15, fontweight='bold')
cat.set_ylabel('Category', fontsize=15, fontweight='bold')
plt.show()

mode_card_type = data_fraud['card_type'].mode()[0]
print(f"The most frequent card type for fraudulent transactions is: {mode_card_type}")

#Card type Vs Number of frauds
fraud_counts = data_fraud['card_type'].value_counts()
sns.set(style="whitegrid")
plt.figure(figsize=(8, 6))
plt.pie(fraud_counts, labels=fraud_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette("bright"))
plt.axis('equal')
plt.title("Card Type vs Number of Frauds", fontsize=16, fontweight='bold')
plt.show()

#High amount transactions as per age
age_group_totals = data_fraud.groupby('age_intervals')['amount'].sum()
age_group_totals = age_group_totals.sort_values(ascending=False)
age_group_totals

top_5_age_groups = age_group_totals.head(5)
plt.figure(figsize=(8, 4))
sns.lineplot(x=top_5_age_groups.index, y=top_5_age_groups.values)
plt.title('Age Groups with Highest Total Amount of Transactions', fontdict = { 'fontsize': 16, 'fontweight':'bold'})
plt.xlabel('Age Group', fontsize=15, fontweight='bold')
plt.ylabel('Total Amount', fontsize=15, fontweight='bold')
plt.xticks(rotation=45)
plt.show()

#Fraudulent Activity by Top 10 Locations
top_10_locations = data_fraud['location'].value_counts().nlargest(10).index
df_location_fraud = data_fraud[data_fraud['location'].isin(top_10_locations)]
plt.figure(figsize=(8, 4))
sns.countplot(data=df_location_fraud, x='location', palette='bright')
plt.xlabel('Location', fontsize=15, fontweight='bold')
plt.ylabel('Count', fontsize=15, fontweight='bold')
plt.title('Fraudulent Activity by Top 10 Locations', fontsize=16, fontweight='bold')
plt.xticks(rotation=45)
plt.show()

data = data.drop(['transaction_description'],axis = 1)

data = data.dropna()

data['Date'] = pd.to_datetime(data['transaction_time'])
data['Year'] = data['Date'].dt.year
data['Month'] = data['Date'].dt.month
data['Day'] = data['Date'].dt.day

def AgeClassify(x):
    if x < 20:
        return 1
    elif 20 <= x < 30:
        return 2
    elif 30 <= x < 40:
        return 3
    elif 40 <= x < 50:
        return 4
    elif 50 <= x < 60:
        return 5
    else:
        return 6

data['customer_age'] = data['customer_age'].apply(AgeClassify)

#Converting Categorical values to numerical values
label_encoder = preprocessing.LabelEncoder()
data['ct']= label_encoder.fit_transform(data['card_type'])
data['loc']= label_encoder.fit_transform(data['location'])
data['pc']= label_encoder.fit_transform(data['purchase_category'])

print("Original and Encoded Card Types:")
print(data[['card_type', 'ct']].drop_duplicates())

print("\nOriginal and Encoded Purchase Categories:")
print(data[['purchase_category', 'pc']].drop_duplicates())

"""MODEL BUILDING"""

#Splitting of the dataset into X and Y
X = data.drop(['is_fraudulent','transaction_time','Date','transaction_id','merchant_id','card_type','purchase_category','location'],axis =1)
Y = data['is_fraudulent']

X

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=13)

# Function to train and evaluate models
def train_and_evaluate_model(model, model_name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = metrics.accuracy_score(y_test, y_pred)
    print(f'{model_name} accuracy: {accuracy}')
    print(metrics.classification_report(y_test, y_pred))

    # Plotting of confusion matrix
    fig, ax = plt.subplots(figsize=(6, 4))
    cm = metrics.confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, cmap="YlGnBu", fmt='g')
    plt.title(f'{model_name} Confusion Matrix', y=1.1)
    ax.xaxis.set_label_position("top")
    plt.tight_layout()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()
    return model

# Defining models
models = {
    "Logistic Regression": LogisticRegression(),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5),
    "Support Vector Machine": SVC(),
    "Random Forest": RandomForestClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=1500, max_depth=4, learning_rate=0.25,
                                                    min_samples_leaf=2, subsample=1, max_features='sqrt',
                                                    random_state=0, verbose=0),
    "XGBoost": xgb.XGBClassifier()
}

# Training and evaluating each model
trained_models = {}
for model_name, model in models.items():
    trained_model = train_and_evaluate_model(model, model_name)
    trained_models[model_name] = trained_model

# Function to make predictions with all models
def predict_with_all_models(trained_models, X_new):
    predictions = {}
    for model_name, model in trained_models.items():
        y_pred = model.predict(X_new)
        predictions[model_name] = y_pred
    return predictions

# Creating a dictionary with sample data
new_data_dict = {
    'customer_id': [1101],  # New customer ID
    'amount': [3000.75],  # Sample purchase amount
    'customer_age': [25],  # Sample customer age
    'Year': [2024],  # Sample year
    'Month': [6],  # Sample month
    'Day': [7], # Sample day
    'ct': [1],  # Sample card type (assuming 1 represents a specific card type)
    'loc': [35],  # Sample location code
    'pc': [3],  # Sample purchase category
}

# Converting the dictionary to a DataFrame
new_data = pd.DataFrame(new_data_dict)

# Displaying the new data
print(new_data)

#Making predictions from the models
predictions = predict_with_all_models(trained_models, new_data)
print(predictions)

# Determining if the transaction is fraudulent based on the predictions from all models
def determine_fraudulent(predictions):
    fraudulent_predictions = {}
    for model_name, prediction in predictions.items():
        if prediction == 1:
            fraudulent_predictions[model_name] = 'Fraudulent'
        else:
            fraudulent_predictions[model_name] = 'Not Fraudulent'
    return fraudulent_predictions


fraudulent_predictions = determine_fraudulent(predictions)

# Printing the result for each model
for model_name, prediction in fraudulent_predictions.items():
    print(f"{model_name}: {prediction}")

import pickle

filename = 'trained_models.sav'
pickle.dump(trained_models, open(filename, 'wb'))

loaded_models = pickle.load(open('trained_models.sav', 'rb'))

predictions = predict_with_all_models(loaded_models, new_data)
print(predictions)

def determine_fraudulent(predictions):
    fraudulent_predictions = {}
    for model_name, prediction in predictions.items():
        if prediction == 1:
            fraudulent_predictions[model_name] = 'Fraudulent'
        else:
            fraudulent_predictions[model_name] = 'Not Fraudulent'
    return fraudulent_predictions

# Determine if the transaction is fraudulent based on the predictions from all models
fraudulent_predictions = determine_fraudulent(predictions)

# Print the result for each model
for model_name, prediction in fraudulent_predictions.items():
    print(f"{model_name}: {prediction}")