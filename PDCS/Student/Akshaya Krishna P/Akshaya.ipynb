{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install pydot graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install distutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install setuptools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClipB6VgvpRQ"
      },
      "outputs": [],
      "source": [
        "# Data Handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "import os\n",
        "\n",
        "#Image Package\n",
        "from PIL import Image\n",
        "\n",
        "# Randomizer\n",
        "import random\n",
        "\n",
        "# Importing TensorFlow\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYQb6CBdPC8x"
      },
      "outputs": [],
      "source": [
        "# keras\n",
        "from keras.models import Sequential, Model                   # Neural network model as a sequence of layers.\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D                              # Convolutional layer\n",
        "from keras.layers import MaxPooling2D                        # Max pooling layer\n",
        "from keras.layers import Flatten                             # Layer used to flatten 2D arrays for fully-connected layers.\n",
        "from keras.layers import Dense                               # This layer adds fully-connected layers to the neural network.\n",
        "from keras.layers import Dropout                             # This serves to prevent overfitting by dropping out a random set of activations.\n",
        "from keras.layers import BatchNormalization                  # This is used to normalize the activations of the neurons.\n",
        "from keras.layers import Activation                          # Layer for activation functions\n",
        "from keras.layers import Rescaling, RandomFlip, RandomRotation\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint   # Classes used to save weights and stop training when improvements reach a limit\n",
        "from keras.models import load_model                          # This helps us to load trained models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlJxTzcuVo7X"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkuxNRUsvifP"
      },
      "outputs": [],
      "source": [
        "# Data Visualization\n",
        "import plotly.subplots as sp\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T70EBlG7t_Du"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrK36lRKvs16"
      },
      "outputs": [],
      "source": [
        "# Resize the input images\n",
        "def imageResizer(paths):\n",
        "  with ThreadPoolExecutor() as executor:\n",
        "    resizedImages = list(executor.map(lambda x: Image.open(x). resize((350,250)), paths))\n",
        "  return resizedImages\n",
        "\n",
        "# Plot a matrix of images in a list\n",
        "def plotImagesList(images, title, subtitle):\n",
        "  fig = sp.make_subplots(rows = 3, cols = 3)\n",
        "  images = imageResizer(images)\n",
        "\n",
        "  traces = []\n",
        "  for i in range(min(9, len(images))):\n",
        "    img = go.Image(z = images[i])\n",
        "    traces.append((img, i//3+1, i%3+1))\n",
        "\n",
        "  fig.add_traces([trace[0] for trace in traces],\n",
        "                rows = [trace[1] for trace in traces],\n",
        "                cols = [trace[2] for trace in traces])\n",
        "\n",
        "  fig.update_layout(\n",
        "      title = {'text': f'<b>{title}<br> <i><sub>{subtitle}</sub></i></b>',\n",
        "               'font': dict(size = 22)},\n",
        "      height =800,\n",
        "      width = 800,\n",
        "      margin = dict(t = 110, l = 80)\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H04d_YxM2hzZ"
      },
      "outputs": [],
      "source": [
        "# Loading training, testing, and validation directories\n",
        "\n",
        "trainDirectory = r\"C:\\Studies\\6th sem\\INFOSYS\\dataset\\archive\\Train\\Train\"\n",
        "testDirectory = r\"C:\\Studies\\6th sem\\INFOSYS\\dataset\\archive\\Test\\Test\"\n",
        "valDirectory= r\"C:\\Studies\\6th sem\\INFOSYS\\dataset\\archive\\Validation\\Validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz9vBfuI3DTY",
        "outputId": "03a60058-dbb5-4354-e2cf-a9d0f076715f"
      },
      "outputs": [],
      "source": [
        "# Directory names\n",
        "\n",
        "directories = {\n",
        "    trainDirectory: 'Train',\n",
        "    testDirectory: 'Test',\n",
        "    valDirectory: 'Validation'\n",
        "    }\n",
        "\n",
        "# Naming subfolders\n",
        "subfolders = ['Healthy', 'Powdery', 'Rust']\n",
        "\n",
        "print('\\n* * * * * Number of files in each folder * * * * *\\n')\n",
        "\n",
        "# Counting the total of pictures inside each subfolder and directory\n",
        "for dir, name in directories.items():\n",
        "    total = 0\n",
        "    for sub in subfolders:\n",
        "        path = os.path.join(dir, sub)\n",
        "        num_files = len([f for f in os.listdir(path) if os.path.join(path, f)])\n",
        "        total += num_files\n",
        "        print(f'\\n{name}/{sub}: {num_files}')\n",
        "    print(f'\\n  Total: {total}')\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "arrDcG-l9Kyh",
        "outputId": "5a503597-49e9-4022-d054-2041e5dea625"
      },
      "outputs": [],
      "source": [
        "uniqueDimensions = set()\n",
        "\n",
        "for directory, name in directories.items():\n",
        "  for subfolder in subfolders:\n",
        "    folderPath = os.path.join(directory, subfolder)\n",
        "\n",
        "    for file in os.listdir(folderPath):\n",
        "      imagePath = os.path.join(folderPath, file)\n",
        "      with Image.open(imagePath) as img:\n",
        "        uniqueDimensions.add(img.size)\n",
        "\n",
        "if len(uniqueDimensions) == 1:\n",
        "    print(f\"\\nAll images have the same dimensions: {uniqueDimensions.pop()}\")\n",
        "else:\n",
        "    print(f\"\\nFound {len(uniqueDimensions)} unique image dimensions: {uniqueDimensions}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne_qKsH2DTU7"
      },
      "outputs": [],
      "source": [
        "dimensionCounts = defaultdict(int)\n",
        "\n",
        "for directory, name in directories.items():\n",
        "  for subfolder in subfolders:\n",
        "    folderPath = os.path.join(directory, subfolder)\n",
        "\n",
        "    for file in os.listdir(folderPath):\n",
        "            imagePath = os.path.join(folderPath, file)\n",
        "            with Image.open(imagePath) as img:\n",
        "              dimensionCounts[img.size] += 1\n",
        "\n",
        "for dimension, count in dimensionCounts.items():\n",
        "  print(f\"\\nDimension {dimension}: {count} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi3kB61OECK2"
      },
      "outputs": [],
      "source": [
        "# Datatype of images\n",
        "\n",
        "all_uint8 = True\n",
        "all_in_range = True\n",
        "\n",
        "for directory, name in directories.items():\n",
        "  for subfolder in subfolders:\n",
        "    folderPath = os.path.join(directory, subfolder)\n",
        "\n",
        "    for file in os.listdir(folderPath):\n",
        "            imagePath = os.path.join(folderPath, file)\n",
        "            with Image.open(imagePath) as img:\n",
        "              img_array = np.array(img)\n",
        "\n",
        "            if img_array.dtype == 'uint8':\n",
        "              all_uint8 = False\n",
        "\n",
        "            if img_array.min() < 0 or img_array.max() > 255:\n",
        "              all_in_range = False\n",
        "\n",
        "if all_uint8:\n",
        "  print(\"All images are of data type uint8\\n\")\n",
        "else:\n",
        "  print(\"Not all images are of data type uint8\\n\")\n",
        "\n",
        "if all_in_range:\n",
        "    print(\"All images have pixel values ranging from 0 to 255\")\n",
        "else:\n",
        "    print(\"Not all images have the same pixel values from 0 to 255\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m2A3cNHJXHU"
      },
      "outputs": [],
      "source": [
        "# Loading the directory for each class in the training dataset\n",
        "\n",
        "trainHealthyDirectory = trainDirectory + \"/\" + 'Healthy'\n",
        "trainRustDirectory = trainDirectory + \"/\" + 'Rust'\n",
        "trainPowderyDirectory = trainDirectory + \"/\" + 'Powdery'\n",
        "\n",
        "# Select 10 random pictures from each directory\n",
        "\n",
        "healthyFiles = random.sample(os.listdir(trainHealthyDirectory), 10)\n",
        "rustFiles = random.sample(os.listdir(trainRustDirectory), 10)\n",
        "powderyFiles = random.sample(os.listdir(trainPowderyDirectory), 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bmuAWpfLWN0"
      },
      "outputs": [],
      "source": [
        "# Healthy Plants Plotting\n",
        "\n",
        "healthyImages = [os.path.join(trainHealthyDirectory, files) for files in healthyFiles]\n",
        "plotImagesList(healthyImages, \"Healthy Plants\", \"Training Dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23Fc14pwLqqc"
      },
      "outputs": [],
      "source": [
        "# Rust Plants Plotting\n",
        "\n",
        "rustImages = [os.path.join(trainRustDirectory, files) for files in rustFiles]\n",
        "plotImagesList(rustImages, \"Rust Plants\", \"Training Dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE8CMZ8ML6fU"
      },
      "outputs": [],
      "source": [
        "# Powdery Plants Plotting\n",
        "\n",
        "powderyImages = [os.path.join(trainPowderyDirectory, files) for files in powderyFiles]\n",
        "plotImagesList(powderyImages, \"Powdery Plants\", \"Training Dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmadfotO5lJ6"
      },
      "source": [
        "***PREPROCESSING STARTS FROM HERE***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rU5WyLLNZFj"
      },
      "outputs": [],
      "source": [
        "# Dataset for Training Data\n",
        "\n",
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    trainDirectory,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['Healthy', 'Powdery', 'Rust'],\n",
        "    batch_size = 16,\n",
        "    image_size = (256, 256),\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    validation_split = 0,\n",
        "    crop_to_aspect_ratio = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP9sFLg_NW_3"
      },
      "outputs": [],
      "source": [
        "# Dataset for Test Data\n",
        "\n",
        "test = tf.keras.utils.image_dataset_from_directory(\n",
        "    testDirectory,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['Healthy', 'Powdery', 'Rust'],\n",
        "    batch_size = 16,\n",
        "    image_size = (256, 256),\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    validation_split = 0,\n",
        "    crop_to_aspect_ratio = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aiaeK0bSjiv"
      },
      "outputs": [],
      "source": [
        "# Dataset for Validation Data\n",
        "\n",
        "validation = tf.keras.utils.image_dataset_from_directory(\n",
        "    valDirectory,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['Healthy', 'Powdery', 'Rust'],\n",
        "    batch_size = 16,\n",
        "    image_size = (256, 256),\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    validation_split = 0,\n",
        "    crop_to_aspect_ratio = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVuUexl2R1wO"
      },
      "outputs": [],
      "source": [
        "print('\\nTraining Dataset:', train)\n",
        "print('\\nTesting Dataset:', test)\n",
        "print('\\nValidation Dataset:', validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHVS9q1PXs7P"
      },
      "outputs": [],
      "source": [
        "# Checking minimum and maximum pixel values in the Validation dataset\n",
        "min_value = float('inf')\n",
        "max_value = -float('inf')\n",
        "\n",
        "for image, label in validation:\n",
        "  batch_min = tf.reduce_min(img)\n",
        "  batch_max = tf.reduce_max(img)\n",
        "\n",
        "  min_value = min(min_value, batch_min.numpy())\n",
        "  max_value = max(max_value, batch_max.numpy())\n",
        "\n",
        "print('\\nMinimum pixel value in the Validation dataset', min_value)\n",
        "print('\\nMaximum pixel value in the Validation dataset', max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2581Dg4ZHra"
      },
      "outputs": [],
      "source": [
        "scaler = Rescaling(1./255) #pixel values to 0 - 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx4gt3LpZOY3"
      },
      "outputs": [],
      "source": [
        "# Rescaling\n",
        "\n",
        "train = train.map(lambda x, y: (scaler(x), y))\n",
        "test = test.map(lambda x, y: (scaler(x), y))\n",
        "validation = validation.map(lambda x, y: (scaler(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC1ajYI9aa7R"
      },
      "outputs": [],
      "source": [
        "# Checking minimum and maximum pixel values in the Validation dataset\n",
        "min_value = float('inf')\n",
        "max_value = -float('inf')\n",
        "\n",
        "for image, label in validation:\n",
        "  batch_min = tf.reduce_min(img)\n",
        "  batch_max = tf.reduce_max(img)\n",
        "\n",
        "  min_value = min(min_value, batch_min.numpy())\n",
        "  max_value = max(max_value, batch_max.numpy())\n",
        "\n",
        "print('\\nMinimum pixel value in the Validation dataset', min_value)\n",
        "print('\\nMaximum pixel value in the Validation dataset', max_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN7t25d65Wa5"
      },
      "source": [
        "***Data Augmentation Starts Here***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Toc3mLzK1xg7"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation pipeline\n",
        "\n",
        "augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.RandomRotation(\n",
        "            factor = (-.25, .3),\n",
        "            fill_mode = 'reflect',\n",
        "            interpolation = 'bilinear',\n",
        "            seed = 42\n",
        "        ),\n",
        "\n",
        "        tf.keras.layers.RandomBrightness(\n",
        "            factor = (-.45, .45),\n",
        "            value_range = (0.0, 1.0),\n",
        "            seed = 42\n",
        "        ),\n",
        "        tf.keras.layers.RandomContrast(\n",
        "            factor = (.5),\n",
        "            seed = 42\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFGYbVdf3hyu"
      },
      "outputs": [],
      "source": [
        "augmentation.build((None, 256, 256, 3)) #Model Build\n",
        "\n",
        "#Plot Model\n",
        "\n",
        "tf.keras.utils.plot_model(augmentation,\n",
        "                          show_shapes = True,\n",
        "                          show_layer_names = True,\n",
        "                          expand_nested = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTKZrPAW5wzB"
      },
      "source": [
        "***CNN STARTS FROM HERE***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORHo0jq2WO6S"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG2eXa9B5zIC"
      },
      "outputs": [],
      "source": [
        "input = Input(shape = (256, 256, 3)) #input layer\n",
        "\n",
        "augmented_inputs = augmentation(input)\n",
        "\n",
        "scaled_inputs = Rescaling(1./255)(augmented_inputs)\n",
        "\n",
        "\n",
        "#layers\n",
        "x = Conv2D(32, (3, 3), strides = 1, padding = 'same')(scaled_inputs)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size = (2,2), padding = 'same')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(64, (5, 5), padding = 'same')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size = (2,2), padding = 'same')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), padding = 'same')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size = (2,2), padding = 'same')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Conv2D(256, (5, 5), padding = 'same')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size = (2,2), padding = 'same')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Conv2D(512, (3, 3), padding = 'same')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size = (2,2), padding = 'same')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# Flattening\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Fully Connected Layers\n",
        "x = Dense(3, activation = 'softmax')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation = 'softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs = input, outputs = output)\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRjQpw-L9Gk9"
      },
      "outputs": [],
      "source": [
        "#earlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
        "                               patience = 5,\n",
        "                               restore_best_weights = True)\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.keras',\n",
        "                            monitor = 'val_accuracy',\n",
        "                            save_best_only = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFdgMur9_yt1"
      },
      "outputs": [],
      "source": [
        "# Training and Testing Model\n",
        "try:\n",
        "    history = model.fit(\n",
        "        train, epochs = 50,\n",
        "        validation_data = test,\n",
        "        callbacks = [early_stopping, checkpoint])\n",
        "except Exception as e:\n",
        "    print(\"An error occurred:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install nbformat --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating subplot\n",
        "fig = make_subplots(rows=1,\n",
        "                    cols=2,\n",
        "                    subplot_titles=['<b>Loss Over Epochs</b>', '<b>Accuracy Over Epochs</b>'],\n",
        "                    horizontal_spacing=0.2)\n",
        "\n",
        "# Loss over epochs\n",
        "train_loss = go.Scatter(x=list(range(len(history.history['loss']))),\n",
        "                        y=history.history['loss'],\n",
        "                        mode='lines',\n",
        "                        line=dict(color='rgba(0, 67, 162, .75)', width=4.75),\n",
        "                        name='Training',\n",
        "                        showlegend = False)\n",
        "\n",
        "val_loss = go.Scatter(x=list(range(len(history.history['val_loss']))),\n",
        "                      y=history.history['val_loss'],\n",
        "                      mode='lines',\n",
        "                      line=dict(color='rgba(255, 132, 0, .75)', width=4.75),\n",
        "                      name='Test',\n",
        "                      showlegend = False)\n",
        "\n",
        "\n",
        "fig.add_trace(train_loss, row=1, col=1)\n",
        "fig.add_trace(val_loss, row=1, col=1)\n",
        "\n",
        "# Accuray over epochs\n",
        "train_acc = go.Scatter(x=list(range(len(history.history['accuracy']))),\n",
        "                       y=history.history['accuracy'],\n",
        "                       mode='lines',\n",
        "                       line=dict(color='rgba(0, 67, 162, .75)', width=4.75),\n",
        "                       name='Training',\n",
        "                       showlegend = True)\n",
        "\n",
        "val_acc = go.Scatter(x=list(range(len(history.history['val_accuracy']))),\n",
        "                     y=history.history['val_accuracy'],\n",
        "                     mode='lines',\n",
        "                     line=dict(color='rgba(255, 132, 0, .75)', width=4.75),\n",
        "                     name='Test',\n",
        "                     showlegend = True)\n",
        "\n",
        "\n",
        "fig.add_trace(train_acc, row=1, col=2)\n",
        "fig.add_trace(val_acc, row=1, col=2)\n",
        "\n",
        "# Updating layout\n",
        "fig.update_layout(\n",
        "    title={'text': '<b>Loss and Accuracy Over Epochs</b>', 'x': 0.025, 'xanchor': 'left'},\n",
        "    margin=dict(t=100),\n",
        "    plot_bgcolor = '#EEF6FF', paper_bgcolor = '#EEF6FF',\n",
        "    height=500, width=1000,\n",
        "    showlegend= True\n",
        ")\n",
        "\n",
        "fig.update_yaxes(title_text = 'Loss', row = 1, col = 1)\n",
        "fig.update_yaxes(title_text = 'Accuracy', row = 1, col = 2)\n",
        "\n",
        "fig.update_xaxes(title_text = 'Epoch', row = 1, col = 1)\n",
        "fig.update_xaxes(title_text = 'Epoch', row = 1, col = 2)\n",
        "\n",
        "# Showing figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_weights('best_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = model.predict(validation)  # Running model on the validation dataset\n",
        "val_loss, val_acc = model.evaluate(validation) # Obtaining Loss and Accuracy on the val dataset\n",
        "\n",
        "print('\\nValidation Loss: ', val_loss)\n",
        "print('\\nValidation Accuracy: ', np.round(val_acc * 100), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading an image from the Validation/ Powdery directory\n",
        "image_path = r\"C:\\Studies\\6th sem\\INFOSYS\\dataset\\archive\\Validation\\Validation\\Powdery\\9bd06de433b285d8.jpg\"\n",
        "original_image = Image.open(image_path)\n",
        "og_width, og_height = original_image.size\n",
        "\n",
        "# Resizing image for optimal performance\n",
        "new_width = int(og_width * .20) # 20% of the original size\n",
        "new_height = int(og_height * .20) # 20% of the original size\n",
        "\n",
        "resized_img = original_image.resize((new_width, new_height))\n",
        "print('Picture of a Powdery Plant: \\n')\n",
        "resized_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manually preprocessing image\n",
        "preprocessed_image = original_image.resize((256, 256))\n",
        "preprocessed_image = np.array(preprocessed_image) / 255.0\n",
        "\n",
        "preds = model.predict(np.expand_dims(preprocessed_image, axis = 0))\n",
        "labels = ['Healthy', 'Powdery', 'Rust']\n",
        "\n",
        "preds_class = np.argmax(preds)\n",
        "preds_label = labels[preds_class]\n",
        "\n",
        "print(f'\\nPredicted Class: {preds_label}')\n",
        "print(f'\\nConfidence Score: {preds[0][preds_class]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading an image from the Validation/ Rust directory\n",
        "image_path = r\"C:\\Studies\\6th sem\\INFOSYS\\dataset\\archive\\Validation\\Validation\\Rust\\8437f01fd3d20f26.jpg\"\n",
        "original_image = Image.open(image_path)\n",
        "og_width, og_height = original_image.size\n",
        "\n",
        "# Resizing image for optimal performance\n",
        "new_width = int(og_width * .20) # 20% of the original size\n",
        "new_height = int(og_height * .20) # 20% of the original size\n",
        "\n",
        "resized_img = original_image.resize((new_width, new_height))\n",
        "print('Picture of a Rust Plant: \\n')\n",
        "resized_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manually preprocessing image\n",
        "preprocessed_image = original_image.resize((256, 256))\n",
        "preprocessed_image = np.array(preprocessed_image) / 255.0\n",
        "\n",
        "preds = model.predict(np.expand_dims(preprocessed_image, axis = 0))\n",
        "labels = ['Healthy', 'Powdery', 'Rust']\n",
        "\n",
        "preds_class = np.argmax(preds)\n",
        "preds_label = labels[preds_class]\n",
        "\n",
        "print(f'\\nPredicted Class: {preds_label}')\n",
        "print(f'\\nConfidence Score: {preds[0][preds_class]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading an image from the Validation/ Healthy directory\n",
        "image_path = r\"C:\\Studies\\6th sem\\INFOSYS\\dataset\\archive\\Validation\\Validation\\Healthy\\9ce01ba1856fc6ad.jpg\"\n",
        "original_image = Image.open(image_path)\n",
        "og_width, og_height = original_image.size\n",
        "\n",
        "# Resizing image for optimal performance\n",
        "new_width = int(og_width * .20) # 20% of the original size\n",
        "new_height = int(og_height * .20) # 20% of the original size\n",
        "\n",
        "resized_img = original_image.resize((new_width, new_height))\n",
        "print('Picture of a Healthy Plant: \\n')\n",
        "resized_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manually preprocessing image\n",
        "preprocessed_image = original_image.resize((256, 256))\n",
        "preprocessed_image = np.array(preprocessed_image) / 255.0\n",
        "\n",
        "preds = model.predict(np.expand_dims(preprocessed_image, axis = 0))\n",
        "labels = ['Healthy', 'Powdery', 'Rust']\n",
        "\n",
        "preds_class = np.argmax(preds)\n",
        "preds_label = labels[preds_class]\n",
        "\n",
        "print(f'\\nPredicted Class: {preds_label}')\n",
        "print(f'\\nConfidence Score: {preds[0][preds_class]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(r'C:\\Studies\\6th sem\\INFOSYS\\project\\plant_disease_classifier.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
