{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188da70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in the training set:\n",
      " 4    2990\n",
      "0    1194\n",
      "3    1082\n",
      "7    1001\n",
      "2     886\n",
      "9     884\n",
      "8     796\n",
      "1     584\n",
      "5     543\n",
      "6     209\n",
      "dtype: int64\n",
      "Data preprocessing complete.\n",
      "Epoch 1/3\n",
      "318/318 [==============================] - 222s 650ms/step - loss: 0.9875 - accuracy: 0.6737 - val_loss: 0.6637 - val_accuracy: 0.7806\n",
      "Epoch 2/3\n",
      "318/318 [==============================] - 171s 537ms/step - loss: 0.3947 - accuracy: 0.8645 - val_loss: 0.3886 - val_accuracy: 0.8635\n",
      "Epoch 3/3\n",
      "318/318 [==============================] - 154s 484ms/step - loss: 0.2213 - accuracy: 0.9261 - val_loss: 0.3727 - val_accuracy: 0.8726\n",
      "171/171 [==============================] - 19s 112ms/step\n",
      "Model training complete and predictions saved to submission.csv.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract the Zip File\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Define the path to the zip file (update the path as necessary)\n",
    "zip_file_path = os.path.join(os.path.expanduser('~'), 'Downloads', 'archive (7).zip')\n",
    "\n",
    "# Define a directory to extract the contents\n",
    "extracted_dir_path = 'extracted_contents'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(extracted_dir_path, exist_ok=True)\n",
    "\n",
    "# Unzip the archive\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_dir_path)\n",
    "\n",
    "# Step 2: Load Images and Labels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_images_and_labels(csv_path, image_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(image_dir, row['Image'])\n",
    "        img = load_img(img_path, target_size=(128, 128))  # Resize images to 128x128\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "        labels.append(row['Label'])\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Construct paths to the CSV files and directories\n",
    "train_csv_path = os.path.join(extracted_dir_path, 'train.csv')\n",
    "test_csv_path = os.path.join(extracted_dir_path, 'test.csv')\n",
    "train_dir = os.path.join(extracted_dir_path, 'train')\n",
    "test_dir = os.path.join(extracted_dir_path, 'test')\n",
    "\n",
    "# Load train images and labels\n",
    "X, y = load_images_and_labels(train_csv_path, train_dir)\n",
    "\n",
    "# Step 3: Split Data into Training and Validation Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Normalize and Prepare Data\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "# Step 5: Preprocess the Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check the distribution of labels in the training set\n",
    "label_counts = pd.Series(y_train.argmax(axis=1)).value_counts()\n",
    "print(\"Label distribution in the training set:\\n\", label_counts)\n",
    "\n",
    "# Perform data augmentation (if necessary)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the data generator to the training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "print(\"Data preprocessing complete.\")\n",
    "\n",
    "# Step 6: Build and Train the Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  # Number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=3, validation_data=(X_val, y_val))\n",
    "\n",
    "# Step 7: Prepare Test Data and Make Predictions\n",
    "X_test, _ = load_images_and_labels(test_csv_path, test_dir)\n",
    "X_test = X_test / 255.0\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Save predictions to submission.csv\n",
    "submission_df = pd.read_csv(os.path.join(extracted_dir_path, 'submission.csv'))\n",
    "submission_df['Label'] = predicted_labels\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Model training complete and predictions saved to submission.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec669a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
