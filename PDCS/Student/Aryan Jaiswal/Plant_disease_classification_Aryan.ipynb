{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ElamXtSmW8h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlRjyDzanYwz",
        "outputId": "7e88a4dd-4604-4d46-fd4e-6b9ff45c09fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 57434 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Unzip the dataset\n",
        "zip_path = '/content/drive/MyDrive/Assignments/Project/train.zip'\n",
        "extract_path = '/content/drive/MyDrive/Assignments/Project/train/'\n",
        "\n",
        "# Check if the directory already exists, if not, unzip the file\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "# Create the training dataset\n",
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    extract_path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u852pt7ni6F",
        "outputId": "c6d922c0-b6f4-45ce-f1dd-7019795bc7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 35154 files belonging to 38 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Assignments/Project/valid',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cipWAvstpMbQ"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oX2OHlQpMzl"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7PHxOrfpM8l"
      },
      "outputs": [],
      "source": [
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuOd4c3qpM_J"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF0ok83rpNB-"
      },
      "outputs": [],
      "source": [
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEj0VWaBpNEZ"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5exML1PpktZ"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaJFqkf0pkhK"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6b0RkArpkYj"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRFe_gQApkLB"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.4)) #To avoid overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcdQF61UpNHy"
      },
      "outputs": [],
      "source": [
        "#Output Layer\n",
        "cnn.add(tf.keras.layers.Dense(units=38,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77i8-N5tp4V6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVoL9N2krxJB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqQjJx8Uo5Ra"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer=tf.keras.optimizers.legacy.Adam(\n",
        "    learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWucajuao5il",
        "outputId": "e19d211f-618f-4c2d-c6ab-45c398264bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 30, 30, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 28, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 14, 14, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 2, 2, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1500)              3073500   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 38)                57038     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7842762 (29.92 MB)\n",
            "Trainable params: 7842762 (29.92 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0-EzMrVqqc_",
        "outputId": "aa09362e-0ec9-4cc9-ad4d-6edf80a1a263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 57434 files belonging to 1 classes.\n",
            "Using 45948 files for training.\n",
            "Found 57434 files belonging to 1 classes.\n",
            "Using 11486 files for validation.\n",
            "Class names: ['train']\n",
            "Number of classes: 1\n",
            "Epoch 1/10\n",
            "1436/1436 [==============================] - 2276s 2s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1436/1436 [==============================] - 1794s 1s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1436/1436 [==============================] - 1850s 1s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1073/1436 [=====================>........] - ETA: 6:51 - loss: 0.0000e+00 - accuracy: 0.0000e+00"
          ]
        }
      ],
      "source": [
        "# Print the class names and number of classes\n",
        "class_names = training_set.class_names\n",
        "num_classes = len(class_names)\n",
        "print(f\"Class names: {class_names}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Defining CNN model\n",
        "cnn = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')  # Ensure this matches the number of classes\n",
        "])\n",
        "\n",
        "cnn.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "training_history = cnn.fit(\n",
        "    training_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWJtaoF8o9oS",
        "outputId": "5f253159-f9d4-4723-b9b5-3d3b4c7db999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 140590 images belonging to 1 classes.\n",
            "Found 35154 images belonging to 38 classes.\n",
            "Found 33 images belonging to 1 classes.\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 678/4393 [===>..........................] - ETA: 2:26:07 - loss: 0.0000e+00 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {accuracy}')\n",
        "\n",
        "# Plotting training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plotting training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}